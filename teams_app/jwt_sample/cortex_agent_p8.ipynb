{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import snowflake.connector\n",
    "\n",
    "HOST = \"FRHSAXD-CFB18747.snowflakecomputing.com\"\n",
    "API_ENDPOINT = \"/api/v2/cortex/agent:run\"\n",
    "API_TIMEOUT = 50000  # in milliseconds\n",
    "\n",
    "CORTEX_SEARCH_SERVICES = \"DASH_DB.DASH_SCHEMA.VEHICLES_INFO\"\n",
    "SEMANTIC_MODELS_SUPPLY_CHAIN = \"@DASH_DB.DASH_SCHEMA.DASH_SEMANTIC_MODELS/supply_chain_semantic_model.yaml\"\n",
    "SEMANTIC_MODELS_SUPPORT_TICKETS = \"@DASH_DB.DASH_SCHEMA.DASH_SEMANTIC_MODELS/support_tickets_semantic_model.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CURRENT_ACCOUNT()</th>\n",
       "      <th>CURRENT_ROLE()</th>\n",
       "      <th>CURRENT_USER()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XIB99769</td>\n",
       "      <td>ACCOUNTADMIN</td>\n",
       "      <td>ANGELCORTEX2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CURRENT_ACCOUNT() CURRENT_ROLE()   CURRENT_USER()\n",
       "0          XIB99769   ACCOUNTADMIN  ANGELCORTEX2025"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Authenticate with private key\n",
    "snow_conn = snowflake.connector.connect(\n",
    "    account=\"FRHSAXD-CFB18747\",\n",
    "    user=\"ANGELCORTEX2025\",\n",
    "    private_key_file=\"/home/angel/sf_keys/rsa_key.p8\",\n",
    "    port=443,\n",
    "    warehouse=\"COMPUTE_WH\",\n",
    "    role=\"ACCOUNTADMIN\",\n",
    ")\n",
    "\n",
    "with snow_conn.cursor() as cur:\n",
    "    df = cur.execute(\"SELECT CURRENT_ACCOUNT(), CURRENT_ROLE(), CURRENT_USER()\").fetch_pandas_all()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SHA256:7KzO++ERgIBiUQc62xv1guqtW/cI39wXjIwHJyCjIkQ='"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cryptography.hazmat.primitives.serialization import load_pem_private_key\n",
    "from cryptography.hazmat.primitives.serialization import Encoding\n",
    "from cryptography.hazmat.primitives.serialization import PublicFormat\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "\n",
    "import base64\n",
    "from getpass import getpass\n",
    "import hashlib\n",
    "# If you generated an encrypted private key, implement this method to return\n",
    "# the passphrase for decrypting your private key. As an example, this function\n",
    "# prompts the user for the passphrase.\n",
    "def get_private_key_passphrase():\n",
    "    return getpass('Passphrase for private key: ')\n",
    "\n",
    "private_key = \"/home/angel/sf_keys/rsa_key.p8\"\n",
    "\n",
    "# Open the private key file.\n",
    "# Replace <private_key_file_path> with the path to your private key file (e.g. /x/y/z/rsa_key.p8).\n",
    "with open(private_key, 'rb') as pem_in:\n",
    "    pemlines = pem_in.read()\n",
    "    try:\n",
    "        # Try to access the private key without a passphrase.\n",
    "        private_key = load_pem_private_key(pemlines, None, default_backend())\n",
    "    except TypeError:\n",
    "        # If that fails, provide the passphrase returned from get_private_key_passphrase().\n",
    "        private_key = load_pem_private_key(pemlines, get_private_key_passphrase().encode(), default_backend())\n",
    "\n",
    "# Get the raw bytes of the public key.\n",
    "public_key_raw = private_key.public_key().public_bytes(Encoding.DER, PublicFormat.SubjectPublicKeyInfo)\n",
    "\n",
    "# Get the sha256 hash of the raw bytes.\n",
    "sha256hash = hashlib.sha256()\n",
    "sha256hash.update(public_key_raw)\n",
    "\n",
    "# Base64-encode the value and prepend the prefix 'SHA256:'.\n",
    "public_key_fp = 'SHA256:' + base64.b64encode(sha256hash.digest()).decode('utf-8')\n",
    "public_key_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated a JWT with the following payload:\n",
      "{'iss': 'FRHSAXD-CFB18747.ANGELCORTEX2025.SHA256:7KzO++ERgIBiUQc62xv1guqtW/cI39wXjIwHJyCjIkQ=', 'sub': 'FRHSAXD-CFB18747.ANGELCORTEX2025', 'iat': 1742953288, 'exp': 1742956828}\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta, timezone, datetime\n",
    "\n",
    "# This example relies on the PyJWT module (https://pypi.org/project/PyJWT/).\n",
    "import jwt\n",
    "\n",
    "# Construct the fully qualified name of the user in uppercase.\n",
    "# - Replace <account_identifier> with your account identifier.\n",
    "#   (See https://docs.snowflake.com/en/user-guide/admin-account-identifier.html .)\n",
    "# - Replace <user_name> with your Snowflake user name.\n",
    "account = \"FRHSAXD-CFB18747\"\n",
    "\n",
    "# Use uppercase for the account identifier and user name.\n",
    "account = account.upper()\n",
    "user = \"ANGELCORTEX2025\".upper()\n",
    "qualified_username = account + \".\" + user\n",
    "\n",
    "# Get the current time in order to specify the time when the JWT was issued and the expiration time of the JWT.\n",
    "now = datetime.now(timezone.utc)\n",
    "\n",
    "# Specify the length of time during which the JWT will be valid. You can specify at most 1 hour.\n",
    "lifetime = timedelta(minutes=59)\n",
    "\n",
    "# Create the payload for the token.\n",
    "payload = {\n",
    "\n",
    "    # Set the issuer to the fully qualified username concatenated with the public key fingerprint (calculated in the  previous step).\n",
    "    \"iss\": qualified_username + '.' + public_key_fp,\n",
    "\n",
    "    # Set the subject to the fully qualified username.\n",
    "    \"sub\": qualified_username,\n",
    "\n",
    "    # Set the issue time to now.\n",
    "    \"iat\": now,\n",
    "\n",
    "    # Set the expiration time, based on the lifetime specified for this object.\n",
    "    \"exp\": now + lifetime\n",
    "}\n",
    "\n",
    "# Generate the JWT. private_key is the private key that you read from the private key file in the previous step when you generated the public key fingerprint.\n",
    "encoding_algorithm=\"RS256\"\n",
    "token = jwt.encode(payload, key=private_key, algorithm=encoding_algorithm)\n",
    "\n",
    "# If you are using a version of PyJWT prior to 2.0, jwt.encode returns a byte string, rather than a string.\n",
    "# If the token is a byte string, convert it to a string.\n",
    "if isinstance(token, bytes):\n",
    "  token = token.decode('utf-8')\n",
    "decoded_token = jwt.decode(token, key=private_key.public_key(), algorithms=[encoding_algorithm])\n",
    "print(\"Generated a JWT with the following payload:\\n{}\".format(decoded_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"model\": \"llama3.1-70b\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Can you show me a breakdown of customer support tickets by service type cellular vs business internet?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "   \"tools\": [\n",
    "            { \"tool_spec\": { \"type\": \"cortex_search\", \"name\": \"vehicles_info_search\" } },\n",
    "            { \"tool_spec\": { \"type\": \"cortex_analyst_text_to_sql\", \"name\": \"support\" } },\n",
    "            { \"tool_spec\": { \"type\": \"cortex_analyst_text_to_sql\", \"name\": \"supply_chain\" } }\n",
    "        ],\n",
    "        \"tool_resources\": {\n",
    "            \"supply_chain\": {\"semantic_model_file\": SEMANTIC_MODELS_SUPPLY_CHAIN},\n",
    "            \"support\": {\"semantic_model_file\": SEMANTIC_MODELS_SUPPORT_TICKETS},\n",
    "            \"vehicles_info_search\": {\n",
    "                \"name\": CORTEX_SEARCH_SERVICES,\n",
    "                \"max_results\": 10,\n",
    "                \"title_column\": \"title\",\n",
    "                \"id_column\": \"relative_path\"\n",
    "            }\n",
    "        }\n",
    "}\n",
    "    \n",
    "resp = requests.post(\n",
    "    url=f\"https://{HOST}/{API_ENDPOINT}\",\n",
    "    json=payload,\n",
    "    headers={\n",
    "        'X-Snowflake-Authorization-Token-Type': 'KEYPAIR_JWT',\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": f'Bearer {token}', \n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message.delta\n",
      "data: {\"id\":\"msg_001\",\"object\":\"message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"tool_use\",\"tool_use\":{\"tool_use_id\":\"toolu_5bdcd3c0\",\"name\":\"support\",\"input\":{\"messages\":[\"role:USER content:{text:{text:\\\"Can you show me a breakdown of customer support tickets by service type cellular vs business internet?\\\"}}\"],\"model\":\"snowflake-hosted-semantic\",\"experimental\":\"\"}}},{\"index\":0,\"type\":\"tool_results\",\"tool_results\":{\"tool_use_id\":\"toolu_5bdcd3c0\",\"content\":[{\"type\":\"json\",\"json\":{\"text\":\"This is our interpretation of your question:\\n\\nShow me the count of support tickets for each service type, specifically comparing Cellular and Business Internet services\",\"suggestions\":[],\"sql\":\"WITH __support_tickets AS (\\n  SELECT\\n    ticket_id,\\n    service_type\\n  FROM dash_db.dash_schema.support_tickets\\n)\\nSELECT\\n  service_type,\\n  COUNT(DISTINCT ticket_id) AS ticket_count\\nFROM __support_tickets\\nWHERE\\n  service_type IN (\\u0027Cellular\\u0027, \\u0027Business Internet\\u0027)\\nGROUP BY\\n  service_type\\n -- Generated by Cortex Analyst\\n;\"}}],\"status\":\"success\",\"name\":\"\"}}]}}\n",
      "\n",
      "event: done\n",
      "data: [DONE]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resp.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_response_to_events(response):\n",
    "    \"\"\"Parse raw SSE response into a list of events\"\"\"\n",
    "    events = []\n",
    "    \n",
    "    # Convert bytes to string if necessary\n",
    "    if isinstance(response, bytes):\n",
    "        response = response.decode(\"utf-8\")\n",
    "    \n",
    "    # Split the response into lines\n",
    "    lines = response.splitlines()\n",
    "    \n",
    "    # Process each line to extract events\n",
    "    for line in lines:\n",
    "        if line.startswith(\"event:\"):\n",
    "            # Extract the event type\n",
    "            event_type = line[len(\"event: \"):].strip()\n",
    "        elif line.startswith(\"data:\"):\n",
    "            # Extract the data and parse it as JSON\n",
    "            try:\n",
    "                data = json.loads(line[len(\"data: \"):].strip())\n",
    "                events.append({\"event\": event_type, \"data\": data})\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Invalid JSON in line: {line}\")\n",
    "    \n",
    "    return events\n",
    "\n",
    "def process_sse_response(response):\n",
    "    \"\"\"Process SSE response\"\"\"\n",
    "    text = \"\"\n",
    "    sql = \"\"\n",
    "    citations = []\n",
    "    \n",
    "    if not response:\n",
    "        return text, sql, citations\n",
    "    if isinstance(response, str):\n",
    "        return text, sql, citations\n",
    "    try:\n",
    "        for event in response:\n",
    "            if event.get('event') == \"message.delta\":\n",
    "                data = event.get('data', {})\n",
    "                delta = data.get('delta', {})\n",
    "                \n",
    "                for content_item in delta.get('content', []):\n",
    "                    content_type = content_item.get('type')\n",
    "                    if content_type == \"tool_results\":\n",
    "                        tool_results = content_item.get('tool_results', {})\n",
    "                        if 'content' in tool_results:\n",
    "                            for result in tool_results['content']:\n",
    "                                if result.get('type') == 'json':\n",
    "                                    text += result.get('json', {}).get('text', '')\n",
    "                                    search_results = result.get('json', {}).get('searchResults', [])\n",
    "                                    for search_result in search_results:\n",
    "                                        citations.append({'source_id':search_result.get('source_id',''), 'doc_id':search_result.get('doc_id', '')})\n",
    "                                    sql = result.get('json', {}).get('sql', '')\n",
    "                    if content_type == 'text':\n",
    "                        text += content_item.get('text', '')\n",
    "                            \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error processing events: {str(e)}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing events: {str(e)}\")\n",
    "        \n",
    "    return text, sql, citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid JSON in line: data: [DONE]\n",
      "Text: I don't know the answer to that question.\n",
      "SQL: \n",
      "Citations: [{'source_id': 1.0, 'doc_id': 'CONV005'}, {'source_id': 2.0, 'doc_id': 'CONV001'}, {'source_id': 3.0, 'doc_id': 'CONV004'}, {'source_id': 4.0, 'doc_id': 'CONV007'}, {'source_id': 5.0, 'doc_id': 'CONV002'}, {'source_id': 6.0, 'doc_id': 'CONV010'}, {'source_id': 7.0, 'doc_id': 'CONV009'}, {'source_id': 8.0, 'doc_id': 'CONV008'}, {'source_id': 9.0, 'doc_id': 'CONV006'}, {'source_id': 10.0, 'doc_id': 'CONV003'}]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "raw_response = resp.content  # Assuming this is the raw SSE response\n",
    "events = parse_response_to_events(raw_response)\n",
    "\n",
    "# Pass the parsed events to the process_sse_response function\n",
    "text, sql, citations = process_sse_response(events)\n",
    "\n",
    "# Print the results\n",
    "print(\"Text:\", text)\n",
    "print(\"SQL:\", sql)\n",
    "print(\"Citations:\", citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'message.delta',\n",
       "  'data': {'id': 'msg_001',\n",
       "   'object': 'message.delta',\n",
       "   'delta': {'content': [{'index': 0,\n",
       "      'type': 'tool_use',\n",
       "      'tool_use': {'tool_use_id': 'toolu_a719d480',\n",
       "       'name': 'search1',\n",
       "       'input': {'scoringConfig': '<nil>',\n",
       "        'experimentalJson': '',\n",
       "        'query': 'Can you show me a breakdown of customer support tickets by service type cellular vs business internet?',\n",
       "        'columns': ['conversation_id'],\n",
       "        'filters': '',\n",
       "        'limit': 10.0,\n",
       "        'requestId': '252e2ed3-129c-4ca1-b2bc-4791ebcc4d83'}}},\n",
       "     {'index': 0,\n",
       "      'type': 'tool_results',\n",
       "      'tool_results': {'tool_use_id': 'toolu_a719d480',\n",
       "       'content': [{'type': 'json',\n",
       "         'json': {'searchResults': [{'doc_title': '',\n",
       "            'text': \"In-depth demo session with DataDriven Co's Analytics team and Business Intelligence managers. Showcase focused on advanced analytics capabilities, custom dashboard creation, and real-time data processing features. Team was particularly impressed with our machine learning integration and predictive analytics models. Competitor comparison requested specifically against Market Leader Z and Innovative Start-up X. Price point falls within their allocated budget range, but team expressed interest in multi-year commitment with corresponding discount structure. Technical questions centered around data warehouse integration and custom visualization capabilities. Action items: prepare detailed competitor feature comparison matrix and draft multi-year pricing proposals with various discount scenarios.\",\n",
       "            'source_id': 1.0,\n",
       "            'doc_id': 'CONV005'},\n",
       "           {'doc_id': 'CONV001',\n",
       "            'doc_title': '',\n",
       "            'text': \"Initial discovery call with TechCorp Inc's IT Director and Solutions Architect. Client showed strong interest in our enterprise solution features, particularly the automated workflow capabilities. The main discussion centered around integration timeline and complexity. They currently use Legacy System X for their core operations and expressed concerns about potential disruption during migration. The team asked detailed questions about API compatibility and data migration tools.\\n\\nAction items include providing a detailed integration timeline document, scheduling a technical deep-dive with their infrastructure team, and sharing case studies of similar Legacy System X migrations. The client mentioned a Q2 budget allocation for digital transformation initiatives. Overall, it was a positive engagement with clear next steps.\",\n",
       "            'source_id': 2.0},\n",
       "           {'doc_title': '',\n",
       "            'text': \"Comprehensive discovery call with GrowthStart Up's CTO and Department Heads. Team of 500+ employees across 3 continents discussed current challenges with their existing solution. Major pain points identified: system crashes during peak usage, limited cross-department reporting capabilities, and poor scalability for remote teams. Deep dive into their current workflow revealed bottlenecks in data sharing and collaboration. Technical requirements gathered for each department. Platform demo focused on scalability features and global team management capabilities. Client particularly interested in our API ecosystem and custom reporting engine. Next steps: schedule department-specific workflow analysis and prepare detailed platform migration plan.\",\n",
       "            'source_id': 3.0,\n",
       "            'doc_id': 'CONV004'},\n",
       "           {'text': \"Contract review meeting with LegalEase Corp's General Counsel, Procurement Director, and IT Manager. Detailed analysis of SLA terms, focusing on uptime guarantees and support response times. Legal team requested specific modifications to liability clauses and data handling agreements. Procurement raised questions about payment terms and service credit structure. Key discussion points included: disaster recovery commitments, data retention policies, and exit clause specifications. IT Manager confirmed technical requirements are met pending final security assessment. Agreement reached on most terms, with only SLA modifications remaining for discussion. Legal team to provide revised contract language by end of week. Overall positive session with clear path to closing.\",\n",
       "            'source_id': 4.0,\n",
       "            'doc_id': 'CONV007',\n",
       "            'doc_title': ''},\n",
       "           {'source_id': 5.0,\n",
       "            'doc_id': 'CONV002',\n",
       "            'doc_title': '',\n",
       "            'text': \"Follow-up call with SmallBiz Solutions' Operations Manager and Finance Director. The primary focus was on pricing structure and ROI timeline. They compared our Basic Package pricing with Competitor Y's small business offering. Key discussion points included monthly vs. annual billing options, user license limitations, and potential cost savings from process automation.\\n\\nThe client requested a detailed ROI analysis focusing on time saved in daily operations, resource allocation improvements, and projected efficiency gains. Budget constraints were clearly communicated, with a maximum budget of $30K for this year. They showed interest in starting with the basic package with room for a potential upgrade in Q4. Next steps include providing a competitive analysis and a customized ROI calculator by next week.\"},\n",
       "           {'doc_title': '',\n",
       "            'text': \"Quarterly strategic review with UpgradeNow Corp's Department Heads and Analytics team. Current implementation meeting basic needs but team requiring more sophisticated analytics capabilities. Deep dive into current usage patterns revealed opportunities for workflow optimization and advanced reporting needs. Users expressed strong satisfaction with platform stability and basic features, but requiring enhanced data visualization and predictive analytics capabilities. Analytics team presented specific requirements: custom dashboard creation, advanced data modeling tools, and integrated BI features. Discussion about upgrade path from current package to Analytics Pro tier. ROI analysis presented showing potential 60% improvement in reporting efficiency. Team to present upgrade proposal to executive committee next month.\",\n",
       "            'source_id': 6.0,\n",
       "            'doc_id': 'CONV010'},\n",
       "           {'doc_id': 'CONV009',\n",
       "            'doc_title': '',\n",
       "            'text': \"Emergency planning session with FastTrack Ltd's Executive team and Project Managers. Critical need for rapid implementation due to current system failure. Team willing to pay premium for expedited deployment and dedicated support team. Detailed discussion of accelerated implementation timeline and resource requirements. Key requirements: minimal disruption to operations, phased data migration, and emergency support protocols. Technical team confident in meeting aggressive timeline with additional resources. Executive sponsor emphasized importance of going live within 30 days. Immediate next steps: finalize expedited implementation plan, assign dedicated support team, and begin emergency onboarding procedures. Team to reconvene daily for progress updates.\",\n",
       "            'source_id': 7.0},\n",
       "           {'text': \"Quarterly business review with GlobalTrade Inc's current implementation team and potential expansion stakeholders. Current implementation in Finance department showcasing strong adoption rates and 40% improvement in processing times. Discussion focused on expanding solution to Operations and HR departments. Users highlighted positive experiences with customer support and platform stability. Challenges identified in current usage: need for additional custom reports and increased automation in workflow processes. Expansion requirements gathered from Operations Director: inventory management integration, supplier portal access, and enhanced tracking capabilities. HR team interested in recruitment and onboarding workflow automation. Next steps: prepare department-specific implementation plans and ROI analysis for expansion.\",\n",
       "            'source_id': 8.0,\n",
       "            'doc_id': 'CONV008',\n",
       "            'doc_title': ''},\n",
       "           {'doc_id': 'CONV006',\n",
       "            'doc_title': '',\n",
       "            'text': \"Extended technical deep dive with HealthTech Solutions' IT Security team, Compliance Officer, and System Architects. Four-hour session focused on API infrastructure, data security protocols, and compliance requirements. Team raised specific concerns about HIPAA compliance, data encryption standards, and API rate limiting. Detailed discussion of our security architecture, including: end-to-end encryption, audit logging, and disaster recovery protocols. Client requires extensive documentation on compliance certifications, particularly SOC 2 and HITRUST. Security team performed initial architecture review and requested additional information about: database segregation, backup procedures, and incident response protocols. Follow-up session scheduled with their compliance team next week.\",\n",
       "            'source_id': 9.0},\n",
       "           {'source_id': 10.0,\n",
       "            'doc_id': 'CONV003',\n",
       "            'doc_title': '',\n",
       "            'text': \"Strategy session with SecureBank Ltd's CISO and Security Operations team. Extremely positive 90-minute deep dive into our Premium Security package. Customer emphasized immediate need for implementation due to recent industry compliance updates. Our advanced security features, especially multi-factor authentication and encryption protocols, were identified as perfect fits for their requirements. Technical team was particularly impressed with our zero-trust architecture approach and real-time threat monitoring capabilities. They've already secured budget approval and have executive buy-in. Compliance documentation is ready for review. Action items include: finalizing implementation timeline, scheduling security audit, and preparing necessary documentation for their risk assessment team. Client ready to move forward with contract discussions.\"}]}}],\n",
       "       'status': 'success',\n",
       "       'name': ''}}]}}},\n",
       " {'event': 'message.delta',\n",
       "  'data': {'id': 'msg_001',\n",
       "   'object': 'message.delta',\n",
       "   'delta': {'content': [{'index': 0, 'type': 'text', 'text': ''}]}}},\n",
       " {'event': 'message.delta',\n",
       "  'data': {'id': 'msg_001',\n",
       "   'object': 'message.delta',\n",
       "   'delta': {'content': [{'index': 0, 'type': 'text', 'text': ''}]}}},\n",
       " {'event': 'message.delta',\n",
       "  'data': {'id': 'msg_001',\n",
       "   'object': 'message.delta',\n",
       "   'delta': {'content': [{'index': 0, 'type': 'text', 'text': ''}]}}},\n",
       " {'event': 'message.delta',\n",
       "  'data': {'id': 'msg_001',\n",
       "   'object': 'message.delta',\n",
       "   'delta': {'content': [{'index': 0, 'type': 'text', 'text': 'I d'}]}}},\n",
       " {'event': 'message.delta',\n",
       "  'data': {'id': 'msg_001',\n",
       "   'object': 'message.delta',\n",
       "   'delta': {'content': [{'index': 0, 'type': 'text', 'text': \"on't\"}]}}},\n",
       " {'event': 'message.delta',\n",
       "  'data': {'id': 'msg_001',\n",
       "   'object': 'message.delta',\n",
       "   'delta': {'content': [{'index': 0, 'type': 'text', 'text': ' know t'}]}}},\n",
       " {'event': 'message.delta',\n",
       "  'data': {'id': 'msg_001',\n",
       "   'object': 'message.delta',\n",
       "   'delta': {'content': [{'index': 0, 'type': 'text', 'text': 'he '}]}}},\n",
       " {'event': 'message.delta',\n",
       "  'data': {'id': 'msg_001',\n",
       "   'object': 'message.delta',\n",
       "   'delta': {'content': [{'index': 0, 'type': 'text', 'text': 'answe'}]}}},\n",
       " {'event': 'message.delta',\n",
       "  'data': {'id': 'msg_001',\n",
       "   'object': 'message.delta',\n",
       "   'delta': {'content': [{'index': 0, 'type': 'text', 'text': 'r to that'}]}}},\n",
       " {'event': 'message.delta',\n",
       "  'data': {'id': 'msg_001',\n",
       "   'object': 'message.delta',\n",
       "   'delta': {'content': [{'index': 0, 'type': 'text', 'text': ' '}]}}},\n",
       " {'event': 'message.delta',\n",
       "  'data': {'id': 'msg_001',\n",
       "   'object': 'message.delta',\n",
       "   'delta': {'content': [{'index': 0, 'type': 'text', 'text': 'question.'}]}}}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
